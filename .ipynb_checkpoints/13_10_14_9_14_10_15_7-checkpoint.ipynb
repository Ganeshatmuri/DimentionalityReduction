{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "13.10#14.9#14.10#15.7.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRj-iblEQGi8"
      },
      "source": [
        "# Load MNIST Data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wp-ij13HQGi-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "outputId": "d18622e9-ddb4-46e2-e337-3bbafde1a110"
      },
      "source": [
        "# MNIST dataset downloaded from Kaggle : \n",
        "#https://www.kaggle.com/c/digit-recognizer/data\n",
        "\n",
        "# Functions to read and show images.\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "   \n",
        "d0 = pd.read_csv('mnist_train.csv')\n",
        "\n",
        "print(d0.head(5)) # print first five rows of d0.\n",
        "\n",
        "# save the labels into a variable l.\n",
        "l = d0['label']\n",
        "\n",
        "# Drop the label feature and store the pixel data in d.\n",
        "d = d0.drop(\"label\",axis=1)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-739ba7ea0946>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0md0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mnist_train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# print first five rows of d0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'mnist_train.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTAYdlDqQGjE"
      },
      "source": [
        "print(d.shape)\n",
        "print(l.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFPxxtvlQGjJ"
      },
      "source": [
        "# display or plot a number.\n",
        "plt.figure(figsize=(7,7))\n",
        "idx = 1\n",
        "\n",
        "grid_data = d.iloc[idx].to_numpy().reshape(28,28)  # reshape from 1d to 2d pixel array\n",
        "plt.imshow(grid_data, interpolation = \"none\", cmap = \"gray\")\n",
        "plt.show()\n",
        "\n",
        "print(l[idx])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uF4ViytmQGjO"
      },
      "source": [
        "#  2D Visualization using PCA "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RWnz578QGjP"
      },
      "source": [
        "# Pick first 15K data-points to work on for time-effeciency.\n",
        "#Excercise: Perform the same analysis on all of 42K data-points.\n",
        "\n",
        "labels = l.head(15000)\n",
        "data = d.head(15000)\n",
        "\n",
        "print(\"the shape of sample data = \", data.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qWXuMacQGjU"
      },
      "source": [
        "# Data-preprocessing: Standardizing the data\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "standardized_data = StandardScaler().fit_transform(data)\n",
        "print(standardized_data.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ho9hboDkQGjb"
      },
      "source": [
        "#find the co-variance matrix which is : A^T * A\n",
        "sample_data = standardized_data\n",
        "\n",
        "# matrix multiplication using numpy\n",
        "covar_matrix = np.matmul(sample_data.T , sample_data)\n",
        "\n",
        "print ( \"The shape of variance matrix = \", covar_matrix.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtlKyc-9QGjg"
      },
      "source": [
        "# finding the top two eigen-values and corresponding eigen-vectors \n",
        "# for projecting onto a 2-Dim space.\n",
        "\n",
        "from scipy.linalg import eigh \n",
        "\n",
        "# the parameter 'eigvals' is defined (low value to heigh value) \n",
        "# eigh function will return the eigen values in asending order\n",
        "# this code generates only the top 2 (782 and 783) eigenvalues.\n",
        "values, vectors = eigh(covar_matrix, eigvals=(782,783))\n",
        "\n",
        "print(\"Shape of eigen vectors = \",vectors.shape)\n",
        "# converting the eigen vectors into (2,d) shape for easyness of further computations\n",
        "vectors = vectors.T\n",
        "\n",
        "print(\"Updated shape of eigen vectors = \",vectors.shape)\n",
        "# here the vectors[1] represent the eigen vector corresponding 1st principal eigen vector\n",
        "# here the vectors[0] represent the eigen vector corresponding 2nd principal eigen vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfQYzUaKQGjl"
      },
      "source": [
        "# projecting the original data sample on the plane \n",
        "#formed by two principal eigen vectors by vector-vector multiplication.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "new_coordinates = np.matmul(vectors, sample_data.T)\n",
        "\n",
        "print (\" resultanat new data points' shape \", vectors.shape, \"X\", sample_data.T.shape,\" = \", new_coordinates.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_5hc304QGjp"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# appending label to the 2d projected data\n",
        "new_coordinates = np.vstack((new_coordinates, labels)).T\n",
        "\n",
        "# creating a new data frame for ploting the labeled points.\n",
        "dataframe = pd.DataFrame(data=new_coordinates, columns=(\"1st_principal\", \"2nd_principal\", \"label\"))\n",
        "print(dataframe.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cz7q6UCbvA4K"
      },
      "source": [
        "import pandas as pd\n",
        "df=pd.DataFrame()\n",
        "df['1st']=[-5.558661,-5.043558,6.193635 ,19.305278]\n",
        "df['2nd']=[-1.558661,-2.043558,2.193635 ,9.305278]\n",
        "df['label']=[1,2,3,4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tphijoAQu4xi"
      },
      "source": [
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "sn.FacetGrid(df, hue=\"label\", size=6).map(plt.scatter, '1st', '2nd').add_legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XGcis_bvzNG"
      },
      "source": [
        "sn.scatterplot(x=\"1st\",y=\"2nd\",hue=\"label\",data=df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGQ6V_LiQGjs"
      },
      "source": [
        "# ploting the 2d data points with seaborn\n",
        "import seaborn as sn\n",
        "sn.FacetGrid(dataframe, hue=\"label\", size=6).map(plt.scatter, '1st_principal', '2nd_principal').add_legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drHOQV6w0Kao"
      },
      "source": [
        "sn.scatterplot(x=\"1st_principal\",y=\"2nd_principal\",legend=\"full\",hue=\"label\",data=dataframe)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g88y_UkgQGjw"
      },
      "source": [
        "# PCA using Scikit-Learn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Od_a_6uQGjx"
      },
      "source": [
        "# initializing the pca\n",
        "from sklearn import decomposition\n",
        "pca = decomposition.PCA()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_Y6hEhEQGjy"
      },
      "source": [
        "# configuring the parameteres\n",
        "# the number of components = 2\n",
        "pca.n_components = 2\n",
        "pca_data = pca.fit_transform(sample_data)\n",
        "\n",
        "# pca_reduced will contain the 2-d projects of simple data\n",
        "print(\"shape of pca_reduced.shape = \", pca_data.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tISf8ZwJQGj1"
      },
      "source": [
        "# attaching the label for each 2-d data point \n",
        "pca_data = np.vstack((pca_data.T, labels)).T\n",
        "\n",
        "# creating a new data fram which help us in ploting the result data\n",
        "pca_df = pd.DataFrame(data=pca_data, columns=(\"1st_principal\", \"2nd_principal\", \"label\"))\n",
        "sn.FacetGrid(pca_df, hue=\"label\", size=6).map(plt.scatter, '1st_principal', '2nd_principal').add_legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfyEnV8-QGj4"
      },
      "source": [
        "# PCA for dimensionality redcution (not for visualization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8blOjJYQGj5"
      },
      "source": [
        "# PCA for dimensionality redcution (non-visualization)\n",
        "\n",
        "pca.n_components = 784\n",
        "pca_data = pca.fit_transform(sample_data)\n",
        "\n",
        "percentage_var_explained = pca.explained_variance_ / np.sum(pca.explained_variance_);\n",
        "\n",
        "cum_var_explained = np.cumsum(percentage_var_explained)\n",
        "\n",
        "# Plot the PCA spectrum\n",
        "plt.figure(1, figsize=(6, 4))\n",
        "\n",
        "plt.clf()\n",
        "plt.plot(cum_var_explained, linewidth=2)\n",
        "plt.axis('tight')\n",
        "plt.grid()\n",
        "plt.xlabel('n_components')\n",
        "plt.ylabel('Cumulative_explained_variance')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# If we take 200-dimensions, approx. 90% of variance is expalined."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTaRTugBQGj7"
      },
      "source": [
        "# t-SNE using Scikit-Learn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bd2bHAybQGj8"
      },
      "source": [
        "# TSNE\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# Picking the top 1000 points as TSNE takes a lot of time for 15K points\n",
        "data_1000 = standardized_data[0:1000,:]\n",
        "labels_1000 = labels[0:1000]\n",
        "\n",
        "model = TSNE(n_components=2, random_state=0)\n",
        "# configuring the parameteres\n",
        "# the number of components = 2\n",
        "# default perplexity = 30\n",
        "# default learning rate = 200\n",
        "# default Maximum number of iterations for the optimization = 1000\n",
        "\n",
        "tsne_data = model.fit_transform(data_1000)\n",
        "\n",
        "\n",
        "# creating a new data frame which help us in ploting the result data\n",
        "tsne_data = np.vstack((tsne_data.T, labels_1000)).T\n",
        "tsne_df = pd.DataFrame(data=tsne_data, columns=(\"Dim_1\", \"Dim_2\", \"label\"))\n",
        "\n",
        "# Ploting the result of tsne\n",
        "sn.FacetGrid(tsne_df, hue=\"label\", size=6).map(plt.scatter, 'Dim_1', 'Dim_2').add_legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-jgsYj8QGj_"
      },
      "source": [
        "model = TSNE(n_components=2, random_state=0, perplexity=50)\n",
        "tsne_data = model.fit_transform(data_1000) \n",
        "\n",
        "# creating a new data fram which help us in ploting the result data\n",
        "tsne_data = np.vstack((tsne_data.T, labels_1000)).T\n",
        "tsne_df = pd.DataFrame(data=tsne_data, columns=(\"Dim_1\", \"Dim_2\", \"label\"))\n",
        "\n",
        "# Ploting the result of tsne\n",
        "sn.FacetGrid(tsne_df, hue=\"label\", size=6).map(plt.scatter, 'Dim_1', 'Dim_2').add_legend()\n",
        "plt.title('With perplexity = 50')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCQ460syQGkC"
      },
      "source": [
        "model = TSNE(n_components=2, random_state=0, perplexity=50,  n_iter=5000)\n",
        "tsne_data = model.fit_transform(data_1000) \n",
        "\n",
        "# creating a new data fram which help us in ploting the result data\n",
        "tsne_data = np.vstack((tsne_data.T, labels_1000)).T\n",
        "tsne_df = pd.DataFrame(data=tsne_data, columns=(\"Dim_1\", \"Dim_2\", \"label\"))\n",
        "\n",
        "# Ploting the result of tsne\n",
        "sn.FacetGrid(tsne_df, hue=\"label\", size=6).map(plt.scatter, 'Dim_1', 'Dim_2').add_legend()\n",
        "plt.title('With perplexity = 50, n_iter=5000')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkcpBB1MQGkF"
      },
      "source": [
        "model = TSNE(n_components=2, random_state=0, perplexity=2)\n",
        "tsne_data = model.fit_transform(data_1000) \n",
        "\n",
        "# creating a new data fram which help us in ploting the result data\n",
        "tsne_data = np.vstack((tsne_data.T, labels_1000)).T\n",
        "tsne_df = pd.DataFrame(data=tsne_data, columns=(\"Dim_1\", \"Dim_2\", \"label\"))\n",
        "\n",
        "# Ploting the result of tsne\n",
        "sn.FacetGrid(tsne_df, hue=\"label\", size=6).map(plt.scatter, 'Dim_1', 'Dim_2').add_legend()\n",
        "plt.title('With perplexity = 2')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvMINUG_QGkH"
      },
      "source": [
        "#Excercise: Run the same analysis using 42K points with various \n",
        "#values of perplexity and iterations.\n",
        "\n",
        "# If you use all of the points, you can expect plots like this blog below:\n",
        "# http://colah.github.io/posts/2014-10-Visualizing-MNIST/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6T6jHFXQGkK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}